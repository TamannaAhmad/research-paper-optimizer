{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Am0MpxzohZOc"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import streamlit as st\n",
        "import nltk\n",
        "import PyPDF2\n",
        "import re\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40DyP6-5hZOk",
        "outputId": "d6aa571f-4707-4208-c4ce-056090d37ace"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    nltk.download('punkt_tab')\n",
        "    nltk.download('stopwords')\n",
        "except:\n",
        "    print(\"Note: NLTK data download failed. If stopwords aren't available, install nltk and run the downloads manually.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrIGF3T2hZOm"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extract text content from a PDF file.\"\"\"\n",
        "    if not os.path.exists(pdf_path):\n",
        "        print(f\"PDF file not found: {pdf_path}\")\n",
        "        return \"\"\n",
        "\n",
        "    if not pdf_path.lower().endswith('.pdf'):\n",
        "        print(f\"File is not a PDF: {pdf_path}\")\n",
        "        return \"\"\n",
        "\n",
        "    try:\n",
        "        text = \"\"\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            if len(reader.pages) == 0:\n",
        "                print(f\"PDF contains no pages: {pdf_path}\")\n",
        "                return \"\"\n",
        "\n",
        "            for page in reader.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text + \"\\n\"\n",
        "\n",
        "        if not text.strip():\n",
        "            print(f\"Extracted empty text from PDF: {pdf_path}\")\n",
        "\n",
        "        return text\n",
        "    except PyPDF2.errors.PdfReadError as e:\n",
        "        print(f\"PDF read error: {e}\")\n",
        "        return \"\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from PDF: {e}\")\n",
        "        return \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnj9MquNhZOq"
      },
      "outputs": [],
      "source": [
        "def extract_abstract(full_text):\n",
        "    \"\"\"Attempt to extract abstract from paper text.\"\"\"\n",
        "    if not full_text or len(full_text) < 500:\n",
        "        return \"\"\n",
        "\n",
        "    # Clean up text\n",
        "    text = re.sub(r'\\s+', ' ', full_text)\n",
        "\n",
        "    # First approach: Look for \"Abstract\" label\n",
        "    abstract_match = re.search(r'(?:abstract|ABSTRACT)[:\\s]+([^\\.]+(?:\\.[^\\.]+){2,10})', text, re.IGNORECASE)\n",
        "    if abstract_match:\n",
        "        abstract = abstract_match.group(1).strip()\n",
        "        if len(abstract) > 100:\n",
        "            return abstract\n",
        "\n",
        "    # Second approach: Get first substantial paragraph (after title)\n",
        "    lines = full_text.split('\\n')\n",
        "    paragraphs = []\n",
        "    current_paragraph = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip():\n",
        "            current_paragraph.append(line.strip())\n",
        "        elif current_paragraph:\n",
        "            paragraphs.append(' '.join(current_paragraph))\n",
        "            current_paragraph = []\n",
        "\n",
        "    if current_paragraph:  # Add the last paragraph\n",
        "        paragraphs.append(' '.join(current_paragraph))\n",
        "\n",
        "    # Skip potential title, author, affiliation paragraphs\n",
        "    start_idx = 0\n",
        "    for i, p in enumerate(paragraphs[:4]):\n",
        "        if len(p) < 100 or any(word in p.lower() for word in ['university', 'department', '@', 'email']):\n",
        "            start_idx = i + 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # Get first substantial paragraph after metadata\n",
        "    for p in paragraphs[start_idx:start_idx+5]:\n",
        "        if len(p) > 150 and len(p) < 2000:\n",
        "            return p\n",
        "\n",
        "    # Last resort: just return the first substantial text\n",
        "    for p in paragraphs:\n",
        "        if len(p) > 200:\n",
        "            return p\n",
        "\n",
        "    return \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LWWXiGaky39"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text, remove_stopwords: bool = True):\n",
        "    if not text or not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    try:\n",
        "        # Normalize whitespace\n",
        "        text = re.sub(r'\\s+', ' ', text.strip().lower())\n",
        "\n",
        "        # Tokenize\n",
        "        tokens = word_tokenize(text)\n",
        "\n",
        "        # Filter tokens\n",
        "        if remove_stopwords:\n",
        "            stop_words = set(stopwords.words('english'))\n",
        "            tokens = [word for word in tokens if word.isalnum() and word not in stop_words and len(word) > 1]\n",
        "        else:\n",
        "            tokens = [word for word in tokens if word.isalnum() and len(word) > 1]\n",
        "\n",
        "        return \" \".join(tokens)\n",
        "    except Exception as e:\n",
        "        print(f\"Text preprocessing failed: {e}\")\n",
        "        return text.lower()  # Return lowercase text as fallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPe2gbrdhZOt"
      },
      "outputs": [],
      "source": [
        "def calculate_relevance(query, abstract, paper_text):\n",
        "    results = {\n",
        "        'combined_score': 0.0,\n",
        "        'abstract_score': 0.0,\n",
        "        'full_text_score': 0.0,\n",
        "        'keyword_score': 0.0,\n",
        "        'status': 'success',\n",
        "        'error': None\n",
        "    }\n",
        "    if not query or not isinstance(query, str):\n",
        "        results['status'] = 'error'\n",
        "        results['error'] = 'Invalid query'\n",
        "        return results\n",
        "\n",
        "    if not abstract:\n",
        "        abstract = \"\"\n",
        "    if not paper_text:\n",
        "        paper_text = \"\"\n",
        "\n",
        "    if not abstract and not paper_text:\n",
        "        results['status'] = 'error'\n",
        "        results['error'] = 'No paper content provided'\n",
        "        return results\n",
        "\n",
        "    try:\n",
        "        # Extract key terms from the query\n",
        "        query_terms = set(preprocess_text(query, True).split())\n",
        "\n",
        "        # Method 1: TF-IDF Vectorization and Cosine Similarity\n",
        "        query_processed = preprocess_text(query)\n",
        "        abstract_processed = preprocess_text(abstract)\n",
        "\n",
        "        # Limit paper text to avoid processing too much text\n",
        "        paper_sample = paper_text[:50000]  # Use first 50K chars to avoid memory issues\n",
        "        paper_processed = preprocess_text(paper_sample)\n",
        "\n",
        "        if not query_processed:\n",
        "            results['status'] = 'error'\n",
        "            results['error'] = 'Query has no valid terms after preprocessing'\n",
        "            return results\n",
        "\n",
        "        # Handle empty processed text\n",
        "        if not abstract_processed:\n",
        "            abstract_processed = \"empty_abstract\"\n",
        "        if not paper_processed:\n",
        "            paper_processed = \"empty_paper\"\n",
        "\n",
        "        documents = [query_processed, abstract_processed, paper_processed]\n",
        "\n",
        "        # Calculate TF-IDF relevance\n",
        "        vectorizer = TfidfVectorizer(min_df=1, ngram_range=(1, 2))\n",
        "        try:\n",
        "            tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "            query_vector = tfidf_matrix[0]\n",
        "            abstract_vector = tfidf_matrix[1]\n",
        "            paper_vector = tfidf_matrix[2]\n",
        "\n",
        "            if abstract_processed != \"empty_abstract\":\n",
        "                abstract_similarity = cosine_similarity(query_vector, abstract_vector)[0][0]\n",
        "            else:\n",
        "                abstract_similarity = 0.0\n",
        "\n",
        "            if paper_processed != \"empty_paper\":\n",
        "                paper_similarity = cosine_similarity(query_vector, paper_vector)[0][0]\n",
        "            else:\n",
        "                paper_similarity = 0.0\n",
        "\n",
        "            results['abstract_score'] = float(abstract_similarity)\n",
        "            results['full_text_score'] = float(paper_similarity)\n",
        "        except Exception as e:\n",
        "            print(f\"TF-IDF calculation failed: {e}\")\n",
        "            results['abstract_score'] = 0.0\n",
        "            results['full_text_score'] = 0.0\n",
        "\n",
        "        # Method 2: Keyword presence\n",
        "        if query_terms:\n",
        "            abstract_text = abstract.lower() if abstract else \"\"\n",
        "            paper_text_sample = paper_text[:100000].lower() if paper_text else \"\"\n",
        "\n",
        "            term_hits = 0\n",
        "            for term in query_terms:\n",
        "                if term in abstract_text:\n",
        "                    term_hits += 2  # Double weight for abstract hits\n",
        "                if term in paper_text_sample:\n",
        "                    term_hits += 1\n",
        "\n",
        "            max_possible_hits = len(query_terms) * 3  # 2 for abstract, 1 for full text\n",
        "            keyword_score = term_hits / max_possible_hits if max_possible_hits > 0 else 0\n",
        "            results['keyword_score'] = keyword_score\n",
        "\n",
        "        # Calculate combined score\n",
        "        abstract_weight = 0.35\n",
        "        fulltext_weight = 0.45\n",
        "        keyword_weight = 0.20\n",
        "\n",
        "        combined_score = (\n",
        "            abstract_weight * results['abstract_score'] +\n",
        "            fulltext_weight * results['full_text_score'] +\n",
        "            keyword_weight * results['keyword_score']\n",
        "        )\n",
        "\n",
        "        results['combined_score'] = float(combined_score)\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating relevance: {e}\")\n",
        "        results['status'] = 'error'\n",
        "        results['error'] = str(e)\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCAOCzqchZOv"
      },
      "outputs": [],
      "source": [
        "def process_paper(query, pdf_path):\n",
        "    results = {\n",
        "        'query': query,\n",
        "        'pdf_path': pdf_path,\n",
        "        'paper_text_length': 0,\n",
        "        'abstract': '',\n",
        "        'abstract_method': '',\n",
        "        'relevance': None,\n",
        "        'status': 'success',\n",
        "        'error': None\n",
        "    }\n",
        "\n",
        "    # Extract text from PDF\n",
        "    paper_text = extract_text_from_pdf(pdf_path)\n",
        "    if not paper_text:\n",
        "        results['status'] = 'error'\n",
        "        results['error'] = 'Failed to extract text from PDF'\n",
        "        return results\n",
        "\n",
        "    results['paper_text_length'] = len(paper_text)\n",
        "\n",
        "    # Extract abstract\n",
        "    abstract = extract_abstract(paper_text)\n",
        "    results['abstract'] = abstract\n",
        "\n",
        "    # Calculate relevance\n",
        "    relevance_results = calculate_relevance(query, abstract, paper_text)\n",
        "    results['relevance'] = relevance_results\n",
        "\n",
        "    if relevance_results['status'] == 'error':\n",
        "        results['status'] = 'warning'\n",
        "        results['error'] = f\"Relevance calculation issue: {relevance_results['error']}\"\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPMRqlbdhZOw"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    print(\"\\n=== Research Paper Relevance Calculator ===\\n\")\n",
        "\n",
        "    try:\n",
        "        # Get input\n",
        "        query = input(\"Enter your search query: \").strip()\n",
        "        if not query:\n",
        "            print(\"Error: Query cannot be empty. Please provide a valid search query.\")\n",
        "            return\n",
        "\n",
        "        pdf_path = input(\"Enter the path to the PDF file: \").strip()\n",
        "        if not os.path.exists(pdf_path):\n",
        "            print(f\"Error: File not found: {pdf_path}\")\n",
        "            return\n",
        "\n",
        "        # Process the paper\n",
        "        print(\"\\nProcessing paper...\")\n",
        "        results = process_paper(query, pdf_path)\n",
        "\n",
        "        # Display results\n",
        "        print(\"\\n=== Results ===\\n\")\n",
        "\n",
        "        if results['status'] == 'error':\n",
        "            print(f\"Error: {results['error']}\")\n",
        "            return\n",
        "\n",
        "        print(f\"Query: {results['query']}\")\n",
        "        print(f\"PDF: {os.path.basename(results['pdf_path'])}\")\n",
        "        print(f\"Extracted text: {results['paper_text_length']} characters\")\n",
        "\n",
        "        if results['abstract']:\n",
        "            print(f\"\\nExtracted abstract ({len(results['abstract'])} chars):\")\n",
        "            print(f\"{results['abstract'][:300]}...\" if len(results['abstract']) > 300 else results['abstract'])\n",
        "        else:\n",
        "            print(\"\\nNo abstract extracted\")\n",
        "\n",
        "        relevance = results['relevance']\n",
        "        if relevance['status'] == 'success':\n",
        "            print(\"\\nRelevance Scores:\")\n",
        "            print(f\"  Combined Score: {relevance['combined_score']:.4f}\")\n",
        "            print(f\"  Abstract Relevance: {relevance['abstract_score']:.4f}\")\n",
        "            print(f\"  Full Text Relevance: {relevance['full_text_score']:.4f}\")\n",
        "            print(f\"  Keyword Match Score: {relevance['keyword_score']:.4f}\")\n",
        "\n",
        "            # Interpret the score\n",
        "            if relevance['combined_score'] > 0.7:\n",
        "                print(\"\\nInterpretation: Highly relevant paper\")\n",
        "            elif relevance['combined_score'] > 0.4:\n",
        "                print(\"\\nInterpretation: Moderately relevant paper\")\n",
        "            elif relevance['combined_score'] > 0.2:\n",
        "                print(\"\\nInterpretation: Somewhat relevant paper\")\n",
        "            else:\n",
        "                print(\"\\nInterpretation: Likely not relevant to your query\")\n",
        "        else:\n",
        "            print(f\"\\nWarning: {relevance['error']}\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nOperation cancelled by user\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOHlN7sEhZOy",
        "outputId": "9f7f455c-087e-4d7d-cbcb-4374a8377257"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Research Paper Relevance Calculator ===\n",
            "\n",
            "Enter your search query: multi-objective reinforcement learning \n",
            "Enter the path to the PDF file: /content/2005.07513.pdf\n",
            "\n",
            "Processing paper...\n",
            "\n",
            "=== Results ===\n",
            "\n",
            "Query: multi-objective reinforcement learning\n",
            "PDF: 2005.07513.pdf\n",
            "Extracted text: 96902 characters\n",
            "\n",
            "Extracted abstract (1242 chars):\n",
            "Many real-world problems require trading off mul- tiple competing objectives. However, these ob- jectives are often in different units and/or scales, which can make it challenging for practitioners to express numerical preferences over objectives in their native units. In this paper we propose a nov...\n",
            "\n",
            "Relevance Scores:\n",
            "  Combined Score: 0.3219\n",
            "  Abstract Relevance: 0.1381\n",
            "  Full Text Relevance: 0.1634\n",
            "  Keyword Match Score: 1.0000\n",
            "\n",
            "Interpretation: Somewhat relevant paper\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOsyE5w8hZO0"
      },
      "outputs": [],
      "source": [
        "def run_relevance_checker(uploaded_file):\n",
        "    st.header(\"Relevance Checker\")\n",
        "    if not uploaded_file:\n",
        "        st.info(\"Please upload a PDF file in the sidebar to begin\")\n",
        "        return\n",
        "    temp_file_path = uploaded_file.name\n",
        "    with open(temp_file_path, \"wb\") as f:\n",
        "        f.write(uploaded_file.getbuffer())\n",
        "\n",
        "    # Get user query\n",
        "    query = st.text_input(\"Enter your research topic or keywords to check relevance against the uploaded paper:\")\n",
        "    \n",
        "    if query and temp_file_path:\n",
        "        # Extract text from PDF\n",
        "        paper_text = extract_text_from_pdf(temp_file_path)\n",
        "        if not paper_text:\n",
        "            st.error(\"Failed to extract text from PDF\")\n",
        "            return\n",
        "\n",
        "        with st.spinner(\"Processing PDF...\"):\n",
        "        # Extract abstract\n",
        "            abstract = extract_abstract(paper_text)\n",
        "\n",
        "        with st.spinner(\"Analysing text...\"):\n",
        "        # Calculate relevance\n",
        "            results = calculate_relevance(query, abstract, paper_text)\n",
        "\n",
        "        # Display results\n",
        "        st.subheader(\"Results\")\n",
        "\n",
        "        if results['status'] == 'error':\n",
        "            st.error(f\"Error: {results['error']}\")\n",
        "            return\n",
        "\n",
        "        if abstract:\n",
        "            with st.expander(\"View Extracted Abstract\"):\n",
        "                st.write(abstract)\n",
        "        else:\n",
        "            st.warning(\"No abstract could be extracted from the paper\")\n",
        "\n",
        "        st.write(\"### Relevance Scores\")\n",
        "        col1, col2, col3, col4 = st.columns(4)\n",
        "        with col1:\n",
        "            st.metric(\"Combined Score\", f\"{results['combined_score']:.3f}\")\n",
        "        with col2:\n",
        "            st.metric(\"Abstract Relevance\", f\"{results['abstract_score']:.3f}\")\n",
        "        with col3:\n",
        "            st.metric(\"Full Text Relevance\", f\"{results['full_text_score']:.3f}\")\n",
        "        with col4:\n",
        "            st.metric(\"Keyword Match\", f\"{results['keyword_score']:.3f}\")\n",
        "\n",
        "        # Interpretation\n",
        "        st.write(\"### Interpretation\")\n",
        "        if results['combined_score'] > 0.7:\n",
        "            st.success(\"Highly relevant paper\")\n",
        "        elif results['combined_score'] > 0.4:\n",
        "            st.info(\"Moderately relevant paper\")\n",
        "        elif results['combined_score'] > 0.2:\n",
        "            st.warning(\"Somewhat relevant paper\")\n",
        "        else:\n",
        "            st.error(\"Likely not relevant to your query\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
